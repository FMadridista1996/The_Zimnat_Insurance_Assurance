{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm_notebook as tn \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type not in ['object', 'datetime64[ns]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train= pd.read_csv('/kaggle/input/train.csv')\npayment_history = pd.read_csv('/kaggle/input/payment_history.csv')\n#client_data = pd.read_csv('/kaggle/input/client_data.csv')\nsub = pd.read_csv('/kaggle/input/sample_sub.csv')\ntest = pd.read_csv('/kaggle/input/sample_sub.csv')\npolicy_data = pd.read_csv('/kaggle/input/policy_data.csv')\ntrain['Lapse' ] = np.where( ( train.Lapse == \"?\" ) & ( train['Lapse Year'] == \"?\" ), 0,1)\ntrain.drop(['Lapse Year'], axis=1, inplace=True)\ntest.drop(['Lapse'], axis=1,inplace=True)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.astype(object)\ntest=test.astype(object)\ntrain=reduce_mem_usage(train)\ntest=reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Lastname(x):\n    x = str(x)\n    a = x.split('_')\n    return a[2]\ndef adresse(x):\n    x = str(x)\n    a = x.split('_')\n    return a[1]\ndef date_from(x):\n    x=str(x)\n    a = x.split(' ')\n    return a[0]\ndef time_from(x):\n    x=str(x)\n    a = x.split(' ')\n    return a[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upper_lim = policy_data['NPR_PREMIUM'].quantile(.95)\nlower_lim = policy_data['NPR_PREMIUM'].quantile(.05)\npolicy_data.loc[(policy_data['NPR_PREMIUM'] > upper_lim),'NPR_PREMIUM'] = upper_lim\npolicy_data.loc[(policy_data['NPR_PREMIUM'] < lower_lim),'NPR_PREMIUM'] = lower_lim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upper_lim = policy_data['NPR_SUMASSURED'].quantile(.95)\nlower_lim = policy_data['NPR_SUMASSURED'].quantile(.05)\npolicy_data.loc[(policy_data['NPR_SUMASSURED'] > upper_lim),'NPR_SUMASSURED'] = upper_lim\npolicy_data.loc[(policy_data['NPR_SUMASSURED'] < lower_lim),'NPR_SUMASSURED'] = lower_lim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upper_lim = policy_data['NLO_AMOUNT'].quantile(.95)\nlower_lim = policy_data['NLO_AMOUNT'].quantile(.05)\npolicy_data.loc[(policy_data['NLO_AMOUNT'] > upper_lim),'NLO_AMOUNT'] = upper_lim\npolicy_data.loc[(policy_data['NLO_AMOUNT'] < lower_lim),'NLO_AMOUNT'] = lower_lim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upper_lim = payment_history['AMOUNTPAID'].quantile(.95)\nlower_lim = payment_history['AMOUNTPAID'].quantile(.05)\npayment_history.loc[(payment_history['AMOUNTPAID'] > upper_lim),'AMOUNTPAID'] = upper_lim\npayment_history.loc[(payment_history['AMOUNTPAID'] < lower_lim),'AMOUNTPAID'] = lower_lim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data = policy_data.fillna(policy_data.median())\npayment_history = payment_history.fillna(policy_data.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data.rename(columns={'NP2_EFFECTDATE':'EFFECTDATE','PPR_PRODCD':'PRODCD','NPR_PREMIUM':'PREMIUM','NPH_LASTNAME':'LASTNAME','CLF_LIFECD':'LIFECD','NSP_SUBPROPOSAL':'SUBPROPOSAL','NPR_SUMASSURED':'SUMASSURED','NLO_TYPE':'TYPE','NLO_AMOUNT':'AMOUNT'}, inplace=True)\npolicy_data['AGCODE'] = policy_data['AAG_AGCODE'].apply(Lastname)\npolicy_data['LOCATCODE'] = policy_data['PCL_LOCATCODE'].apply(Lastname)\npolicy_data['OCCUPATION_'] = policy_data['OCCUPATION'].apply(adresse)\npolicy_data['CATEGORY_'] = policy_data['CATEGORY'].apply(adresse)\npolicy_data['TYPE_'] = policy_data['TYPE'].apply(adresse)\npolicy_data.drop(['AAG_AGCODE'],axis=1, inplace=True )\npolicy_data.drop(['PCL_LOCATCODE'],axis=1, inplace=True )\npolicy_data.drop(['OCCUPATION'],axis=1, inplace=True )\npolicy_data.drop(['CATEGORY'],axis=1, inplace=True )\npolicy_data.drop(['TYPE'],axis=1, inplace=True )\npolicy_data['EFFECTDATE'] = pd.to_datetime(policy_data['EFFECTDATE'])\npolicy_data['EFFECTDATE_year'] = policy_data['EFFECTDATE'].dt.year\npolicy_data['EFFECTDATE_month'] = policy_data['EFFECTDATE'].dt.month\npolicy_data['EFFECTDATE_day'] = policy_data['EFFECTDATE'].dt.day\npolicy_data['EFFECTDATE_weekday'] = policy_data['EFFECTDATE'].dt.weekday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EFFECTDATE_month = pd.get_dummies(policy_data['EFFECTDATE_month'] , prefix='EFFECTDATE_month')\npolicy_data = pd.concat([policy_data,EFFECTDATE_month],axis=1)\npolicy_data.drop(['EFFECTDATE_month'],axis=1 , inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del EFFECTDATE_month\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data['EFFECTDATE_dayofweek_name']=policy_data['EFFECTDATE'].dt.day_name()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OCCUPATION = pd.get_dummies(policy_data['OCCUPATION_'] , prefix='OCCUPATION')\n#policy_data = pd.concat([policy_data,OCCUPATION],axis=1)\n#policy_data.drop(['OCCUPATION_'],axis=1 , inplace = True)\nCategory = pd.get_dummies(policy_data['CATEGORY_'] , prefix='Category')\npolicy_data = pd.concat([policy_data,Category],axis=1)\npolicy_data.drop(['CATEGORY_'],axis=1 , inplace = True)\nBranch_code = pd.get_dummies(policy_data['LOCATCODE'] , prefix='Branch_code')\npolicy_data = pd.concat([policy_data,Branch_code],axis=1)\npolicy_data.drop(['LOCATCODE'],axis=1 , inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data['total']=policy_data['PREMIUM']+policy_data['AMOUNT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del Category , Branch_code\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PRODCD = pd.get_dummies(policy_data['PRODCD'] , prefix='PRODCD')\npolicy_data = pd.concat([policy_data,PRODCD],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del PRODCD\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NLO_TYPE = pd.get_dummies(policy_data['TYPE_'] , prefix='TYPE')\npolicy_data = pd.concat([policy_data,NLO_TYPE],axis=1)\npolicy_data.drop(['TYPE_'],axis=1 , inplace = True)\nCLF_LIFECD = pd.get_dummies(policy_data['LIFECD'] , prefix='LIFECD')\npolicy_data = pd.concat([policy_data,CLF_LIFECD],axis=1)\npolicy_data.drop(['LIFECD'],axis=1 , inplace = True)\nNP2_EFFECTDATE_year = pd.get_dummies(policy_data['EFFECTDATE_year'] , prefix='EFFECTDATE_year')\npolicy_data = pd.concat([policy_data,NP2_EFFECTDATE_year],axis=1)\npolicy_data.drop(['EFFECTDATE_year'],axis=1 , inplace = True)\nSUBPROPOSAL = pd.get_dummies(policy_data['SUBPROPOSAL'] , prefix='SUBPROPOSAL')\npolicy_data = pd.concat([policy_data,SUBPROPOSAL],axis=1)\npolicy_data.drop(['SUBPROPOSAL'],axis=1 , inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del NLO_TYPE , CLF_LIFECD , NP2_EFFECTDATE_year \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data['LASTNAME_']=policy_data['LASTNAME'].apply(Lastname)\npolicy_data['PRODCD_']=policy_data['PRODCD'].apply(Lastname)\npolicy_data.drop(['LASTNAME'],axis=1,inplace=True)\npolicy_data.drop(['PRODCD'],axis=1,inplace=True)\npolicy_data.rename(columns={'LASTNAME_':'LASTNAME'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"client_data.fillna(method='ffill', inplace=True)\nclient_data.dropna(inplace=True)\nclient_data.rename(columns={'NPH_TITLE':'TITLE','NPH_SEX':'SEX','NPH_BIRTHDATE':'BIRTHDATE'}, inplace=True)\nclient_data['LASTNAME'] = client_data['NPH_LASTNAME'].apply(Lastname)\nclient_data['ADDRESS1'] = client_data['NAD_ADDRESS1'].apply(adresse)\nclient_data['ADDRESS2'] = client_data['NAD_ADDRESS2'].apply(adresse)\nclient_data.drop(['NPH_LASTNAME'],axis=1, inplace=True )\nclient_data.drop(['NAD_ADDRESS1'],axis=1, inplace=True )\nclient_data.drop(['NAD_ADDRESS2'],axis=1, inplace=True )\ntitle = pd.get_dummies(client_data['TITLE'] , prefix='Title')\nclient_data = pd.concat([client_data,title],axis=1)\nclient_data.drop(['TITLE'],axis=1 , inplace = True)\nSex = pd.get_dummies(client_data['SEX'] , prefix='Sex')\nclient_data = pd.concat([client_data,Sex],axis=1)\nclient_data.drop(['SEX'],axis=1 , inplace = True)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"payment_history['PREMIUMDUEDATE'].fillna(payment_history['PREMIUMDUEDATE'].value_counts().idxmax(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\npayment_history['DATEPAID_date'] = payment_history['DATEPAID'].apply(date_from)\npayment_history['DATEPAID_time'] = payment_history['DATEPAID'].apply(time_from)\npayment_history['POSTDATE_date'] = payment_history['POSTDATE'].apply(date_from)\npayment_history['POSTDATE_time'] = payment_history['POSTDATE'].apply(time_from)\npayment_history['PREMIUMDUEDATE_date'] = payment_history['PREMIUMDUEDATE'].apply(date_from)\npayment_history['PREMIUMDUEDATE_time'] = payment_history['PREMIUMDUEDATE'].apply(time_from)\npayment_history['DATEPAID'] = pd.to_datetime(payment_history['DATEPAID'])\npayment_history['POSTDATE'] = pd.to_datetime(payment_history['POSTDATE'])\npayment_history['PREMIUMDUEDATE'] = pd.to_datetime(payment_history['PREMIUMDUEDATE'])\npayment_history['paid_year'] = payment_history['DATEPAID'].dt.year\npayment_history['paid_month'] = payment_history['DATEPAID'].dt.month\npayment_history['paid_day'] = payment_history['DATEPAID'].dt.day\npayment_history['paid_weekday'] = payment_history['DATEPAID'].dt.weekday\npayment_history['post_year'] = payment_history['POSTDATE'].dt.year\npayment_history['post_month'] = payment_history['POSTDATE'].dt.month\npayment_history['post_day'] = payment_history['POSTDATE'].dt.day\npayment_history['post_weekday'] = payment_history['POSTDATE'].dt.weekday\npayment_history['premium_year'] = payment_history['PREMIUMDUEDATE'].dt.year\npayment_history['premium_month'] = payment_history['PREMIUMDUEDATE'].dt.month\npayment_history['premium_day'] = payment_history['PREMIUMDUEDATE'].dt.day\npayment_history['premium_weekday'] = payment_history['PREMIUMDUEDATE'].dt.weekday\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"premium_year = pd.get_dummies(payment_history['premium_year'] , prefix='premium_year')\npayment_history = pd.concat([payment_history,premium_year],axis=1)\npayment_history.drop(['premium_year'],axis=1 , inplace = True)\npaid_year = pd.get_dummies(payment_history['paid_year'] , prefix='paid_year')\npayment_history = pd.concat([payment_history,paid_year],axis=1)\npayment_history.drop(['paid_year'],axis=1 , inplace = True)\npost_year = pd.get_dummies(payment_history['post_year'] , prefix='post_year')\npayment_history = pd.concat([payment_history,post_year],axis=1)\npayment_history.drop(['post_year'],axis=1 , inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del premium_year , paid_year , post_year\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"premium_month = pd.get_dummies(payment_history['premium_month'] , prefix='premium_month')\npayment_history = pd.concat([payment_history,premium_month],axis=1)\npayment_history.drop(['premium_month'],axis=1 , inplace = True)\npost_month = pd.get_dummies(payment_history['post_month'] , prefix='post_month')\npayment_history = pd.concat([payment_history,post_month],axis=1)\npayment_history.drop(['post_month'],axis=1 , inplace = True)\npaid_month = pd.get_dummies(payment_history['paid_month'] , prefix='paid_month')\npayment_history = pd.concat([payment_history,paid_month],axis=1)\npayment_history.drop(['paid_month'],axis=1 , inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del premium_month , post_month , paid_month \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"payment_history['PREMIUMDUEDATE_dayofweek_name']=payment_history['PREMIUMDUEDATE'].dt.day_name()\npayment_history['DATEPAID_dayofweek_name']=payment_history['DATEPAID'].dt.day_name()\npayment_history['POSTDATE_dayofweek_name']=payment_history['POSTDATE'].dt.day_name()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## sample train dataset\na = policy_data[['LASTNAME','OCCUPATION_']]\n\n## Frequency Encoding title variable\nb = a.groupby(['LASTNAME']).size().reset_index()\nb.columns = ['LASTNAME', 'Freq_Encoded_OCCUPATION_']\npolicy_data = pd.merge(policy_data,b,on = 'LASTNAME',how = 'left')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del a , b \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_train = policy_data[['Policy ID','AMOUNT']]\n## Mean encoding \nx = sample_train.groupby(['Policy ID'])['AMOUNT'].mean().reset_index()\nx = x.rename(columns={\"AMOUNT\" : \"AMOUNT\" +\"_Mean_Encoded\"})\npolicy_data = pd.merge(policy_data,x,on = 'Policy ID',how = 'left')\npolicy_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sample_train , x \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"## sample train dataset\na = policy_data[['AGCODE','Policy ID']]\n\n## Frequency Encoding title variable\nb = a.groupby(['Policy ID']).size().reset_index()\nb.columns = ['Policy ID', 'Freq_Encoded_AGCODE']\npolicy_data = pd.merge(policy_data,b,on = 'Policy ID',how = 'left')\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''## sample train dataset\na = policy_data[['PRODCD_','LASTNAME']]\n\n## Frequency Encoding title variable\nb = a.groupby(['PRODCD_']).size().reset_index()\nb.columns = ['PRODCD_', 'Freq_Encoded_PRODCD']\npolicy_data = pd.merge(policy_data,b,on = 'PRODCD_',how = 'left')'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"## sample train dataset\na = policy_data[['SUBPROPOSAL','Policy ID']]\n\n## Frequency Encoding title variable\nb = a.groupby(['Policy ID']).size().reset_index()\nb.columns = ['Policy ID', 'Freq_Encoded_SUBPROPOSAL']\npolicy_data = pd.merge(policy_data,b,on = 'Policy ID',how = 'left')\npolicy_data.head()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''sample_train = policy_data[['Policy ID','PREMIUM']]\n## Mean encoding \nx = sample_train.groupby(['Policy ID'])['PREMIUM'].mean().reset_index()\nx = x.rename(columns={\"PREMIUM\" : \"PREMIUM\" +\"_Mean_Encoded\"})\npolicy_data = pd.merge(policy_data,x,on = 'Policy ID',how = 'left')\npolicy_data.head()'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"sample_train = policy_data[['Policy ID','SUMASSURED']]\n## Mean encoding \nx = sample_train.groupby(['Policy ID'])['SUMASSURED'].mean().reset_index()\nx = x.rename(columns={\"SUMASSURED\" : \"SUMASSURED\" +\"_Mean_Encoded\"})\npolicy_data = pd.merge(policy_data,x,on = 'Policy ID',how = 'left')\npolicy_data.head()\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"sample_train = payment_history[['Policy ID','AMOUNTPAID']]\n## Mean encoding \nx = sample_train.groupby(['Policy ID'])['AMOUNTPAID'].mean().reset_index()\nx = x.rename(columns={\"AMOUNTPAID\" : \"AMOUNTPAID\"+\"_Mean_Encoded\"})\npayment_history = pd.merge(payment_history,x,on = 'Policy ID',how = 'left')\"\"\"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_cat_job(x):\n    if x>0.07:\n        return 0 \n    elif x<0.7 and x>0.01 : \n        return 1 \n    elif x<0.01 and x>0.001 : \n        return 2 \n    elif x<0.001 and x>0.0001 : \n        return 3\n    elif x<0.0001 and x>0.00001 : \n        return 4\n    else : \n        return 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data['OCCUPATION_cat']=np.zeros(policy_data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = list(policy_data['OCCUPATION_'].unique())\nb={}\nfor elem in a:\n    b[elem]=policy_data['OCCUPATION_'].value_counts(elem)\nfor i in tn(range(240)):\n    a=list(b.values())[i][i]\n    policy_data['OCCUPATION_cat'][i]=set_cat_job(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"occupation = pd.get_dummies(policy_data['OCCUPATION_cat'] , prefix='occupation')\npolicy_data = pd.concat([policy_data,occupation],axis=1)\npolicy_data.drop(['OCCUPATION_cat'],axis=1 , inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#policy_data.drop(['LASTNAME'],axis=1,inplace=True)\npolicy_data.drop(['PRODCD_'],axis=1 , inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data.drop(['AGCODE','OCCUPATION_'],axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.astype(object)\ntest=test.astype(object)\ntrain=reduce_mem_usage(train)\ntest=reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(right=policy_data.reset_index(), how='left', on='Policy ID')\ntrain = train.merge(right=payment_history.reset_index(), how='left', on='Policy ID')\n\"\"\"c.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in c.columns]\nd.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in d.columns]\nc.reset_index(inplace=True)\nd.reset_index(inplace=True)\ntrain = train.merge(right=c.reset_index(), how='left', on='Policy ID')\ntrain = train.merge(right=d.reset_index(), how='left', on='Policy ID')\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.merge(right=policy_data.reset_index(), how='left', on='Policy ID')\ntest = test.merge(right=payment_history.reset_index(), how='left', on='Policy ID')\n\"\"\"c.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in c.columns]\nd.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in d.columns]\nc.reset_index(inplace=True)\nd.reset_index(inplace=True)\nc.rename(columns={'Policy_ID':'Policy ID'},inplace=True)\nd.rename(columns={'Policy_ID':'Policy ID'},inplace=True)\ntest = test.merge(right=c.reset_index(), how='left', on='Policy ID')\ntest = test.merge(right=d.reset_index(), how='left', on='Policy ID')\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del policy_data , payment_history , occupation , a , b \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop_duplicates(subset =\"Policy ID\", keep ='first', inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.fillna(test.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['PREMIUMDUEDATE_time'].fillna(test['PREMIUMDUEDATE_time'].value_counts().idxmax(), inplace=True)\ntest['PREMIUMDUEDATE_date'].fillna(test['PREMIUMDUEDATE_date'].value_counts().idxmax(), inplace=True)\ntest['POSTDATE_time'].fillna(test['POSTDATE_time'].value_counts().idxmax(), inplace=True)\ntest['POSTDATE_date'].fillna(test['POSTDATE_date'].value_counts().idxmax(), inplace=True)\ntest['DATEPAID_time'].fillna(test['DATEPAID_time'].value_counts().idxmax(), inplace=True)\ntest['DATEPAID_date'].fillna(test['DATEPAID_date'].value_counts().idxmax(), inplace=True)\ntest['PREMIUMDUEDATE'].fillna(test['PREMIUMDUEDATE'].value_counts().idxmax(), inplace=True)\ntest['POSTDATE'].fillna(test['POSTDATE'].value_counts().idxmax(), inplace=True)\ntest['DATEPAID'].fillna(test['DATEPAID'].value_counts().idxmax(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in tn(test.columns):\n    if test[col].dtype != 'object':\n        test[col]=test[col].astype(object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test = test.astype(object)\ntest=reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.fillna(train.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['index_x'],axis=1,inplace=True)\ntrain.drop(['index_y'],axis=1,inplace=True)\ntest.drop(['index_x'],axis=1,inplace=True)\ntest.drop(['index_y'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['PREMIUMDUEDATE_time'].fillna(train['PREMIUMDUEDATE_time'].value_counts().idxmax(), inplace=True)\ntrain['PREMIUMDUEDATE_date'].fillna(train['PREMIUMDUEDATE_date'].value_counts().idxmax(), inplace=True)\ntrain['POSTDATE_time'].fillna(train['POSTDATE_time'].value_counts().idxmax(), inplace=True)\ntrain['POSTDATE_date'].fillna(train['POSTDATE_date'].value_counts().idxmax(), inplace=True)\ntrain['DATEPAID_time'].fillna(train['DATEPAID_time'].value_counts().idxmax(), inplace=True)\ntrain['DATEPAID_date'].fillna(train['DATEPAID_date'].value_counts().idxmax(), inplace=True)\ntrain['PREMIUMDUEDATE'].fillna(train['PREMIUMDUEDATE'].value_counts().idxmax(), inplace=True)\ntrain['POSTDATE'].fillna(train['POSTDATE'].value_counts().idxmax(), inplace=True)\ntrain['DATEPAID'].fillna(train['DATEPAID'].value_counts().idxmax(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['index'],axis=1,inplace=True)\ntest.drop(['index'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test=test.astype(object)\ntest=reduce_mem_usage(test)\n#train=train.astype(object)\ntrain=reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfor f in tn(train.columns):\n    if train[f].dtype!='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train[f].values))  \n        train[f] = lbl.transform(list(train[f].values)) \nfor f in tn(test.columns):\n    if test[f].dtype!='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(test[f].values))  \n        test[f] = lbl.transform(list(test[f].values)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = train['Lapse']\nX = train.drop(['Lapse'],axis=1,inplace=False)\n#X=X.astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=X.astype(float)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'objective' :'binary',\n    'learning_rate' : 0.01,\n    'num_leaves' : 120,\n    'feature_fraction': 0.4, \n    'bagging_fraction': 0.4, \n    'bagging_freq':1,\n    'boosting_type' : 'gbdt',\n    'metric': 'binary_logloss',\n    'max_depth' : -1,\n    'seed':0,\n    'lambda_l2':0.4\n}\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgbm\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(X,Y,  random_state=7, test_size=0.33)\n    \n    # making lgbm datasets for train and valid\nd_train = lgbm.Dataset(X_train, Y_train)\nd_valid = lgbm.Dataset(X_valid, Y_valid)\n    \n    # training with early stop\nbst = lgbm.train(params, d_train, 500, valid_sets=[d_valid], verbose_eval=50, early_stopping_rounds=100)\n    \n    # making prediciton for one column\n    \npreds = bst.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['Lapse']=preds\nsub.Lapse.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\ndef create_submission(submission_file, submission_name):\n    submission_file.to_csv(submission_name+\".csv\" , index=False)\n    return FileLink(submission_name+\".csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_submission(sub, 'Zimnat48')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[sub['Lapse']>0.5].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}